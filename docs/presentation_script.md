# 🎤 마음이음 프로젝트 발표 대본 & 예상 질문

---

## 📋 발표 개요

- **총 발표 시간**: 약 15-20분 (슬라이드당 1-1.5분)
- **슬라이드 수**: 14장
- **권장 속도**: 천천히, 명확하게

---

# 🎬 발표 대본

---

## 슬라이드 1: 표지 (30초)

### 대본

> 안녕하세요. 저는 오늘 **"AI 휴머노이드 반려로봇 기반 노인 정신건강 진단 및 증진 플랫폼"**, 프로젝트명 **마음이음**에 대해 발표하겠습니다.
> 
> 마음이음은 "어르신의 마음을 읽고, 가족과 연결한다"는 의미를 담고 있습니다.

### 💡 발표 포인트
- 첫인상이 중요! 자신감 있게 시작
- 프로젝트명의 의미 강조

---

## 슬라이드 2: 목차 (30초)

### 대본

> 오늘 발표는 총 8개 파트로 구성되어 있습니다.
> 
> 먼저 프로젝트 개요와 문제 정의를 통해 **왜 이 프로젝트가 필요한지** 설명드리고,
> 핵심 기능과 시스템 아키텍처로 **무엇을 어떻게 만들 것인지** 보여드리겠습니다.
> 
> 그리고 기술 스택, 데이터베이스 설계, 화면 설계를 거쳐
> 마지막으로 개발 일정과 기대효과로 마무리하겠습니다.

### 💡 발표 포인트
- 전체 흐름을 미리 안내하여 청중의 이해를 도움
- "왜-무엇을-어떻게" 구조 강조

---

## 슬라이드 3: 프로젝트 개요 (1분 30초)

### 대본

> 먼저 프로젝트 개요입니다.
> 
> **프로젝트 목표**는 멀티모달 AI 기술, 즉 영상 인식, 음성 인식, 그리고 대형 언어 모델을 활용해서 **독거노인의 정서적 고립을 해소**하고, **보호자에게 실시간 모니터링 환경을 제공**하는 통합 케어 플랫폼을 개발하는 것입니다.
> 
> 핵심 가치는 네 가지입니다.
> 
> 첫째, **정서 케어** - AI가 먼저 다가가서 어르신의 감정을 읽고 공감합니다.
> 둘째, **인지 건강** - 게임과 회상 치료를 통해 치매를 예방합니다.
> 셋째, **가족 연결** - 떨어져 사는 보호자에게 부모님 상태를 실시간으로 전달합니다.
> 넷째, **위험 감지** - 우울이나 고립 같은 위험 신호를 조기에 발견해서 알립니다.
> 
> 대상 사용자는 크게 두 그룹입니다.
> **시니어**, 즉 65세 이상 독거노인분들과
> **보호자**, 부모님과 떨어져 살면서 걱정되시는 자녀분들입니다.

### 💡 발표 포인트
- "멀티모달 AI"를 쉽게 풀어서 설명
- 네 가지 핵심 가치를 손가락으로 세면서 강조
- 두 사용자 그룹의 니즈 차이 설명

### ❓ 예상 질문

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **왜 "휴머노이드 반려로봇"이라고 했는데 로봇이 아니라 웹앱인가요?** | "현재 버전은 웹앱 형태의 소프트웨어이고, 향후 실제 로봇 하드웨어와 연동하는 것을 목표로 합니다. 지금은 태블릿이나 스마트 디스플레이에서 로봇 캐릭터가 대화하는 형태입니다." |
| 2 | **65세 이상으로 타겟을 잡은 이유는?** | "통계적으로 65세 이상이 고령자로 분류되고, 이 연령대부터 독거 비율과 우울증 유병률이 급격히 증가합니다." |
| 3 | **기존 시니어 케어 앱과의 차별점은?** | "기존 앱들은 사용자가 먼저 앱을 켜고 조작해야 하지만, 저희는 얼굴만 감지되면 AI가 먼저 인사합니다. 또한 표정 분석을 통해 감정에 맞는 대화를 제공합니다." |
| 4 | **보호자와 시니어 앱을 분리한 이유는?** | "UX 요구사항이 완전히 다르기 때문입니다. 시니어는 큰 버튼과 음성 중심, 보호자는 데이터 시각화와 빠른 액션이 필요합니다." |

---

## 슬라이드 4: 문제 정의 및 필요성 (1분 30초)

### 대본

> 그렇다면 왜 이 프로젝트가 필요할까요?
> 
> 먼저 통계를 보시면, 우리나라 65세 이상 고령 인구는 **21.1%**로 이미 초고령사회에 진입했습니다.
> **독거노인 가구는 228만**에 달하고, **노인 우울증 유병률은 무려 28%**입니다.
> 네 명 중 한 명 이상이 우울증을 겪고 있다는 뜻입니다.
> 특히 충격적인 건, **노인 자살률이 여전히 OECD 1위**라는 점입니다.
> 그리고 **치매 환자는 97만 명**으로 곧 100만 명을 넘어설 전망입니다.
> 
> 이런 통계 뒤에는 네 가지 핵심 문제가 있습니다.
> 
> 첫째, **정서적 고립**. "하루 종일 혼자 있어요"라고 호소하시는 분들이 많습니다. 이게 우울감으로 이어지고, 인지 기능 저하를 가속화합니다.
> 
> 둘째, **디지털 소외**. "스마트폰이 어려워요"라며 기존 서비스에 접근조차 못 하시는 분들이 많습니다.
> 
> 셋째, **보호자의 불안**. "엄마 상태를 모르겠어요"라며 멀리서 돌봄의 한계를 느끼는 자녀분들이 많습니다.
> 
> 넷째, **조기 발견 실패**. "알았을 땐 이미..." 정신건강 위험 신호를 놓치는 경우가 많습니다.

### 💡 발표 포인트
- **21.1%** - "초고령사회 진입" 강조
- **28%** - "네 명 중 한 명 이상" 체감되게 표현
- **97만명** - "곧 100만 명" 임박함 강조
- 숫자는 또박또박 천천히, "OECD 1위"에서 잠깐 멈추기

### ❓ 예상 질문

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **통계 출처가 어디인가요?** | "2025년 기준 통계청 인구동향조사, 보건복지부 노인실태조사, 중앙치매센터 치매현황 자료입니다." |
| 2 | **28%면 굉장히 높은 수치인데, 기준이 뭔가요?** | "노인실태조사에서 우울 증상 척도(GDS 등)를 기준으로 측정한 수치입니다. 임상 진단 기준보다는 넓지만, 그만큼 잠재적 위험군이 많다는 의미입니다." |
| 3 | **초고령사회 기준이 뭔가요?** | "65세 이상 인구 비율 20% 이상이 초고령사회입니다. 21.1%면 이미 진입한 상태입니다." |
| 4 | **독거노인 228만이면 이전보다 많이 늘었나요?** | "네, 지속적으로 증가 추세입니다. 핵가족화와 고령화가 동시에 진행되면서 매년 증가하고 있습니다." |
| 5 | **이 문제들을 기술로 해결할 수 있다고 생각하는 근거는?** | "기술이 모든 것을 해결할 순 없지만, 24시간 말동무 역할과 데이터 기반 조기 감지는 기술이 가장 잘할 수 있는 영역입니다." |

---

## 슬라이드 5: 솔루션 차별점 (1분)

### 대본

> 그래서 마음이음은 기존 솔루션과 무엇이 다른지 설명드리겠습니다.
> 
> **첫 번째, 능동적 AI입니다.**
> 기존 챗봇은 사용자가 말을 걸어야 반응하지만, 마음이음은 웹캠이 얼굴을 감지하면 **AI가 먼저 "어르신, 오셨어요?"하고 인사**합니다.
> 
> **두 번째, 감정 기반 케어입니다.**
> 기존 서비스는 키워드 기반으로 응답하지만, 저희는 **표정을 분석해서 "오늘 기분이 안 좋아 보이세요"라며 감정에 맞는 위로**를 제공합니다.
> 
> **세 번째, 보호자 실시간 연결입니다.**
> 기존에는 자녀가 직접 전화해야 부모님 상태를 알 수 있었지만, 저희는 **대시보드에서 감정 추이, 게임 점수, 활동량을 실시간으로 확인**할 수 있습니다.
> 
> **네 번째, 위험 신호 자동 감지입니다.**
> 문제가 발생한 후에야 인지하는 게 아니라, **우울 감정이 3일 연속 감지되면 자동으로 보호자에게 알림**을 보냅니다.

### 💡 발표 포인트
- 기존 vs 마음이음 대비 구조로 명확하게
- "먼저 인사", "3일 연속" 같은 구체적 기능 강조

### ❓ 예상 질문

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **얼굴 감지 정확도는 어느 정도인가요?** | "DeepFace 라이브러리를 사용하는데, 정면 얼굴 감지 정확도는 99% 이상입니다. 감지 실패 시 버튼으로 시작하는 대안도 제공합니다." |
| 2 | **감정 분석의 정확도와 한계는?** | "DeepFace의 감정 인식 정확도는 약 70-80%입니다. 완벽하지 않기 때문에, 단일 분석이 아니라 3일간의 추이를 보고 판단합니다." |
| 3 | **3일 연속이라는 기준은 어떻게 정했나요?** | "정신건강의학적으로 2주 이상 지속되는 우울이 진단 기준이지만, 조기 개입을 위해 3일로 설정했습니다. 이 값은 설정에서 조절 가능합니다." |
| 4 | **비슷한 경쟁 서비스가 있나요?** | "효돌이 같은 시니어 로봇이 있지만, 주로 단순 대화와 일정 알림 기능입니다. 실시간 감정 분석과 보호자 대시보드를 통합한 서비스는 차별화됩니다." |

---

## 슬라이드 6: 핵심 기능 - 시니어 앱 (1분 30초)

### 대본

> 이제 핵심 기능을 설명드리겠습니다. 먼저 시니어 앱입니다.
> 
> **첫 번째, 얼굴 감지 웨이크업입니다.**
> 어르신이 화면 앞에 오시면 웹캠이 얼굴을 감지하고, AI가 먼저 "어르신, 오셨어요?"라고 인사합니다.
> 대기 모드에서 활성 모드로 자동 전환되어, 버튼을 누를 필요가 없습니다.
> 
> **두 번째, AI 말동무 대화입니다.**
> Google Gemini 기반으로 자연스러운 대화를 제공합니다.
> 특히 **장기 기억 시스템**이 있어서, "지난번에 미역국 드셨다고 했는데, 오늘은 뭐 드셨어요?"처럼 연속성 있는 대화가 가능합니다.
> 
> **세 번째, 실시간 감정 분석입니다.**
> DeepFace로 표정을 분석해서 7가지 감정을 인식합니다.
> 슬픈 표정이 감지되면 "오늘 기분이 안 좋아 보이세요"라며 맞춤 위로를 제공합니다.
> 
> 그 외에도 **인지 훈련 게임**, **회상 치료**, **음성 인터페이스**가 있습니다.
> 모든 기능은 큰 버튼, 높은 명암 대비, 음성 우선으로 시니어 친화적으로 설계했습니다.

### 💡 발표 포인트
- 상위 3개 기능을 자세히, 나머지는 간단히
- "버튼을 누를 필요가 없다" - 편의성 강조
- "연속성 있는 대화" - 기존 챗봇과 차별점

### ❓ 예상 질문

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **장기 기억은 어떻게 구현하나요?** | "대화 중 중요 정보(이름, 가족관계, 좋아하는 음식 등)를 Gemini가 추출하고, DB에 저장합니다. 다음 대화 시 프롬프트에 포함시켜 맥락을 유지합니다." |
| 2 | **7가지 감정이 뭔가요?** | "Happy, Sad, Angry, Neutral, Fear, Surprise, Disgust입니다. DeepFace의 기본 감정 분류를 사용합니다." |
| 3 | **인지 훈련 게임은 어떤 것들이 있나요?** | "카드 맞추기(기억력), 초성 퀴즈(언어능력), 숫자 암기(작업기억), 간단 계산(계산능력) 4가지입니다." |
| 4 | **회상 치료가 뭔가요?** | "과거의 긍정적 기억을 자극하는 치료법입니다. '어릴 적 살던 동네는 어땠나요?' 같은 질문으로 장기 기억을 활성화합니다." |
| 5 | **음성 인식 정확도는?** | "Web Speech API를 사용하는데, 조용한 환경에서 90% 이상입니다. 인식 실패 시 다시 말씀해달라고 안내합니다." |

---

## 슬라이드 7: 핵심 기능 - 보호자 대시보드 (1분 30초)

### 대본

> 다음은 보호자 대시보드입니다.
> 
> **첫 번째, 감정 추이 모니터링입니다.**
> 부모님의 감정 변화를 일별, 주별 그래프로 확인할 수 있습니다.
> "이번 주에 우울한 날이 많았구나"를 한눈에 파악할 수 있습니다.
> 
> **두 번째, 인지능력 점수 추적입니다.**
> 게임 점수를 기반으로 기억력, 집중력, 언어력을 추적합니다.
> 점수가 지속적으로 하락하면 인지 저하를 조기에 발견할 수 있습니다.
> 
> **세 번째, 위험 신호 알림입니다.**
> 우울 감정이 3일 연속 감지되거나, 3일간 접속이 없으면 자동으로 알림이 갑니다.
> 보호자가 먼저 연락하거나 방문할 수 있도록 합니다.
> 
> **네 번째, 원격 알림 전송입니다.**
> "어머니, 혈압약 드실 시간이에요!" 같은 메시지를 보내면,
> **0.1초 만에** 부모님 화면에 팝업이 뜹니다. Supabase Realtime 덕분입니다.
> 
> 그 외에도 **주간/월간 리포트**와 **시니어-보호자 연결 관리** 기능이 있습니다.

### 💡 발표 포인트
- "한눈에 파악" - 데이터 시각화의 가치
- "0.1초" - 실시간성 강조
- 보호자 입장에서의 필요성 설명

### ❓ 예상 질문

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **0.1초가 가능한 이유는?** | "Supabase Realtime이 WebSocket 기반이라 폴링 없이 즉시 전달됩니다. 실제로는 네트워크 상황에 따라 다르지만, 대부분 1초 이내입니다." |
| 2 | **한 시니어에 여러 보호자가 연결 가능한가요?** | "네, 초대 코드 시스템으로 자녀, 손자녀, 요양보호사 등 여러 명이 연결 가능합니다." |
| 3 | **프라이버시 문제는 없나요?** | "시니어가 초대 코드를 생성하고 승인해야만 연결됩니다. 또한 Row Level Security로 권한이 있는 사람만 데이터에 접근할 수 있습니다." |
| 4 | **알림을 너무 자주 보내면 시니어가 귀찮아하지 않을까요?** | "보호자가 직접 보내는 것이라 남용 가능성은 낮고, 시니어도 가족의 관심으로 받아들일 것으로 예상합니다. 필요시 알림 빈도 제한 기능도 추가할 수 있습니다." |

---

## 슬라이드 8: 시스템 아키텍처 (1분)

### 대본

> 시스템 아키텍처입니다.
> 
> 크게 세 개의 레이어로 구성됩니다.
> 
> **맨 위는 프론트엔드**, Vercel에 배포합니다.
> 시니어 앱과 보호자 대시보드, 둘 다 React로 개발합니다.
> 
> **가운데는 백엔드**, Supabase를 사용합니다.
> Supabase는 BaaS, Backend as a Service로,
> **인증, 데이터베이스, 실시간 통신, 서버리스 함수**를 모두 제공합니다.
> 별도의 백엔드 서버를 구축할 필요가 없어서 개발 속도가 빨라집니다.
> 
> **맨 아래는 AI 서버**, Render에 배포합니다.
> Flask로 만든 Python 서버에서 DeepFace 감정 분석을 처리합니다.
> 대화 AI는 Supabase Edge Function에서 Google Gemini API를 호출합니다.

### 💡 발표 포인트
- 세 레이어 구조를 위에서 아래로 설명
- "별도 백엔드 없이" - Supabase 선택 이유
- 각 서비스의 역할 명확히

### ❓ 예상 질문

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **Supabase를 선택한 이유는?** | "Firebase와 달리 PostgreSQL 기반이라 관계형 쿼리가 가능하고, 무료 티어가 충분합니다. 또한 Realtime과 Row Level Security가 내장되어 있습니다." |
| 2 | **왜 AI 서버를 따로 뒀나요?** | "DeepFace는 Python 라이브러리이고, 무거운 ML 모델이라 Edge Function보다 전용 서버가 적합합니다. 또한 GPU 활용 가능성도 고려했습니다." |
| 3 | **Vercel과 Render를 선택한 이유는?** | "둘 다 무료 티어가 있고, GitHub 연동 시 자동 배포가 됩니다. Vercel은 React에 최적화되어 있고, Render는 Python 서버 배포가 간편합니다." |
| 4 | **확장성은 어떤가요?** | "Supabase와 Render 모두 유료 플랜으로 업그레이드하면 자동 스케일링이 가능합니다. 현재 구조에서 큰 변경 없이 확장 가능합니다." |

---

## 슬라이드 9: 기술 스택 (1분)

### 대본

> 기술 스택입니다.
> 
> **프론트엔드**는 React 19와 Vite를 사용합니다.
> Chart.js로 감정 그래프를, Web Speech API로 음성 인식과 합성을 구현합니다.
> 
> **백엔드**는 Supabase입니다.
> PostgreSQL 데이터베이스, 역할 기반 인증, 실시간 구독, 서버리스 Edge Function을 모두 활용합니다.
> 
> **AI 서비스**는 두 가지입니다.
> 대화에는 Google Gemini 2.5를, 감정 분석에는 DeepFace를 사용합니다.
> Flask로 API 서버를 만들고 Python으로 ML 처리를 합니다.
> 
> **배포**는 Vercel과 Render를 사용하고, Git으로 버전 관리와 CI/CD를 구축합니다.
> 
> 기술 선정 기준은 **무료 또는 저비용**, **한국어 지원**, **개발 생산성**이었습니다.

### 💡 발표 포인트
- 네 영역을 빠르게 훑기
- 선정 기준 3가지로 마무리

### ❓ 예상 질문

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **Gemini를 선택한 이유는? GPT는요?** | "Gemini는 무료 API를 제공하고, 한국어 성능이 우수합니다. GPT는 유료이고, 프로젝트 비용을 최소화하기 위해 Gemini를 선택했습니다." |
| 2 | **DeepFace 외에 다른 감정 분석 라이브러리는?** | "FER, OpenCV 등이 있지만, DeepFace가 정확도가 높고 얼굴 감지와 감정 분석을 함께 제공해서 선택했습니다." |
| 3 | **React 19를 선택한 이유는?** | "가장 널리 사용되는 프레임워크이고, 취업 시장에서도 수요가 높습니다. 컴포넌트 기반 개발로 재사용성도 좋습니다." |
| 4 | **테스트 프레임워크는 뭘 쓰나요?** | "프론트엔드는 Jest와 React Testing Library, 백엔드 로직은 Supabase의 내장 테스트 기능을 활용할 예정입니다." |

---

## 슬라이드 10: 데이터베이스 설계 (1분)

### 대본

> 데이터베이스 설계입니다. 총 6개의 테이블로 구성됩니다.
> 
> **users 테이블**이 중심입니다. 시니어와 보호자를 role 필드로 구분합니다.
> 
> **connections 테이블**은 시니어와 보호자의 연결 관계를 저장합니다. 초대 코드와 승인 상태를 관리합니다.
> 
> **emotion_logs 테이블**이 핵심 데이터입니다. 감정 분석 결과를 시간별로 저장해서 추이 분석에 사용합니다.
> 
> **game_scores 테이블**은 인지 훈련 게임 점수를 저장합니다.
> 
> **memories 테이블**은 AI가 추출한 장기 기억을 저장합니다.
> 
> **daily_reports 테이블**은 일일 리포트를 저장하고, 위험 레벨을 판정합니다.
> 
> 모든 테이블에 **Row Level Security**를 적용해서, 본인 데이터와 연결된 보호자만 접근할 수 있도록 합니다.

### 💡 발표 포인트
- 6개 테이블을 빠르게 훑기
- emotion_logs가 핵심임을 강조
- RLS로 보안 처리

### ❓ 예상 질문

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **emotion_logs가 너무 많이 쌓이면?** | "인덱스를 걸어 조회 성능을 확보하고, 오래된 데이터는 daily_reports로 집계 후 아카이빙할 수 있습니다." |
| 2 | **notifications 테이블은 없나요?** | "네, 있습니다. 슬라이드에는 주요 테이블만 표시했고, 실제로는 notifications 테이블도 있어서 알림 이력을 저장합니다." |
| 3 | **Row Level Security가 뭔가요?** | "행 단위 보안 정책입니다. SQL 정책으로 '본인 데이터만 조회 가능', '연결된 보호자만 조회 가능' 같은 규칙을 설정합니다." |
| 4 | **정규화 수준은?** | "3정규형을 기본으로 하되, 조회 성능을 위해 daily_reports처럼 일부 비정규화했습니다." |

---

## 슬라이드 11: 화면 설계 (1분)

### 대본

> 화면 설계입니다.
> 
> **시니어 앱**은 두 가지 모드가 있습니다.
> 
> **Idle 모드**는 대기 화면입니다. 로봇 캐릭터가 "쉬고 있어요..."라고 표시되고, 얼굴이 감지되면 자동으로 Active 모드로 전환됩니다.
> 
> **Active 모드**는 대화 화면입니다. 큰 버튼 4개로 대화, 게임, 추억, 기분 분석 기능에 접근합니다.
> 모든 UI는 **큰 글씨, 높은 명암 대비, 음성 안내**로 시니어 친화적입니다.
> 
> **보호자 대시보드**는 데이터 중심입니다.
> 상단에 부모님 상태와 감정 그래프, 중간에 약 알림과 안부 전하기 버튼, 하단에 알림 목록이 있습니다.
> 한 화면에서 **상태 파악과 빠른 액션**이 모두 가능하도록 설계했습니다.

### 💡 발표 포인트
- Idle/Active 모드 전환 설명
- 시니어 vs 보호자 UI 철학 차이 강조

### ❓ 예상 질문

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **시니어 친화 UI 기준이 뭔가요?** | "최소 16pt 이상 글씨, 명암비 4.5:1 이상, 터치 영역 44px 이상, 복잡한 제스처 지양 등 접근성 가이드라인을 따랐습니다." |
| 2 | **실제 시니어 사용자 테스트는?** | "개발 완료 후 주변 어르신들께 테스트를 요청할 예정입니다. 피드백을 반영해 UI를 개선하겠습니다." |
| 3 | **다크모드는 없나요?** | "시니어는 밝은 화면이 가독성이 좋아서 라이트 모드만 지원합니다. 보호자 앱은 향후 다크모드를 추가할 수 있습니다." |
| 4 | **모바일 반응형인가요?** | "시니어 앱은 태블릿 기준, 보호자 앱은 모바일/데스크톱 반응형으로 설계했습니다." |

---

## 슬라이드 12: 개발 일정 (1분)

### 대본

> 개발 일정입니다. 총 4주로 계획했습니다.
> 
> **1주차**는 설계 및 환경 구축입니다.
> 요구사항 분석, 설계 문서 작성, Supabase 프로젝트 생성, React 프로젝트 세팅을 합니다.
> 
> **2주차**는 시니어 앱 개발입니다.
> Idle/Active 모드, 얼굴 감지 웨이크업, AI 대화, 감정 분석을 구현합니다.
> 
> **3주차**는 보호자 대시보드 개발입니다.
> 대시보드 레이아웃, 감정 추이 차트, 실시간 알림, 위험 신호 감지를 구현합니다.
> 
> **4주차**는 통합 및 배포입니다.
> 전체 테스트, Vercel과 Render 배포, README 문서화를 완료합니다.
> 
> 각 주차별로 **마일스톤**을 설정해서 진행 상황을 체크합니다.

### 💡 발표 포인트
- 4주 일정을 빠르게 훑기
- 마일스톤 단위로 관리한다는 점 강조

### ❓ 예상 질문

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **4주가 현실적인가요?** | "핵심 기능 MVP 기준입니다. 기존에 만들어둔 게임 컴포넌트와 AI 연동 코드를 재사용하고, Supabase로 백엔드 개발 시간을 단축합니다." |
| 2 | **혼자 개발하나요, 팀인가요?** | "현재는 1인 개발이고, 풀스택으로 진행합니다. 필요시 역할 분담도 가능한 구조로 설계했습니다." |
| 3 | **일정이 지연되면?** | "필수 기능과 선택 기능을 구분해뒀습니다. 지연 시 선택 기능(리포트 PDF 다운로드 등)을 후순위로 미룹니다." |
| 4 | **테스트는 언제 하나요?** | "각 주차 개발 완료 시 단위 테스트를 하고, 4주차에 통합 테스트를 집중적으로 진행합니다." |

---

## 슬라이드 13: 기대 효과 (1분)

### 대본

> 마지막으로 기대 효과입니다.
> 
> **사회적 기대 효과**는 네 가지입니다.
> 
> 첫째, **정서적 고립 해소**. AI가 24시간 말동무가 되어 독거노인의 외로움을 완화합니다.
> 
> 둘째, **치매 조기 발견**. 인지능력 점수 추적으로 이상 징후를 조기에 감지합니다.
> 
> 셋째, **가족 유대 강화**. 실시간 모니터링과 원격 소통으로 떨어져 있어도 연결을 유지합니다.
> 
> 넷째, **위험 조기 대응**. 우울이나 고립 같은 위험 신호를 자동으로 감지해서 알립니다.
> 
> **기술적으로는** 풀스택 개발, 멀티모달 AI, 실시간 시스템, 클라우드 배포 경험을 얻을 수 있습니다.
> 
> 마음이음은 **"어르신의 마음을 읽고, 가족과 연결하는 AI 반려 로봇"**입니다.

### 💡 발표 포인트
- 사회적 가치와 기술적 가치 모두 언급
- 슬로건으로 마무리

### ❓ 예상 질문

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **실제 효과를 어떻게 측정할 건가요?** | "사용자 만족도 설문, 감정 로그 분석, 보호자 피드백을 수집할 계획입니다. 장기적으로는 우울 점수 변화도 추적할 수 있습니다." |
| 2 | **수익 모델은 있나요?** | "현재는 포트폴리오 프로젝트이지만, B2B로 요양원이나 지자체에 제공하거나, 프리미엄 기능 구독 모델을 고려할 수 있습니다." |
| 3 | **이 프로젝트로 배운 점은?** | "요구사항 분석부터 배포까지 전 과정을 경험했습니다. 특히 사용자 중심 설계와 실시간 시스템 구축 경험이 값졌습니다." |
| 4 | **향후 발전 계획은?** | "실제 로봇 하드웨어 연동, 더 정교한 감정 분석 모델, 다국어 지원 등을 고려하고 있습니다." |

---

## 슬라이드 14: 감사합니다 (30초)

### 대본

> 이상으로 마음이음 프로젝트 발표를 마치겠습니다.
> 
> 경청해주셔서 감사합니다.
> 
> 질문 있으시면 말씀해주세요.

### 💡 발표 포인트
- 간결하게 마무리
- 질문을 기다리는 자세로 잠시 멈춤

---

# 📝 종합 예상 질문 TOP 10

발표 전체를 관통하는 핵심 질문들입니다.

| # | 질문 | 답변 가이드 |
|---|------|-------------|
| 1 | **이 프로젝트를 하게 된 계기는?** | "고령화 사회 문제와 AI 기술에 관심이 있었고, 실제로 도움이 되는 서비스를 만들고 싶었습니다. 주변 어르신들의 외로움을 보면서 기획했습니다." |
| 2 | **가장 어려웠던 점은?** | "시니어와 보호자라는 완전히 다른 두 사용자의 니즈를 하나의 플랫폼에서 만족시키는 설계가 어려웠습니다." |
| 3 | **가장 자신 있는 기능은?** | "얼굴 감지 웨이크업입니다. 버튼을 누르지 않아도 AI가 먼저 인사하는 경험이 다른 서비스와 확실히 다릅니다." |
| 4 | **보안은 어떻게 처리하나요?** | "Supabase의 Row Level Security로 데이터 접근을 제어하고, 연결은 초대 코드 + 승인 방식으로 이중 확인합니다." |
| 5 | **오프라인에서는 작동하나요?** | "현재 버전은 온라인 필수입니다. 향후 PWA로 오프라인 캐싱을 추가할 수 있습니다." |
| 6 | **API 비용은 얼마나 드나요?** | "Gemini는 무료 티어 내에서 충분하고, Supabase/Vercel/Render도 무료 티어를 사용합니다. 현재 비용은 0원입니다." |
| 7 | **다른 언어 지원 계획은?** | "현재는 한국어만 지원합니다. Gemini가 다국어를 지원하므로 프롬프트 수정만으로 확장 가능합니다." |
| 8 | **유사 서비스와 비교했을 때 장단점은?** | "장점은 감정 분석 + 보호자 연동 통합, 단점은 아직 실제 로봇이 아닌 소프트웨어라는 점입니다." |
| 9 | **이 프로젝트가 취업에 어떻게 도움이 될까요?** | "풀스택 개발 역량, AI 연동 경험, 실시간 시스템 구축 경험을 증명할 수 있습니다. 사회적 가치도 어필 포인트입니다." |
| 10 | **코드는 공개하나요?** | "GitHub에 오픈소스로 공개할 예정입니다. README와 기술 문서도 함께 제공합니다." |

---

# 🎯 발표 팁

## 발표 전 체크리스트

- [ ] 슬라이드 순서 확인
- [ ] 발표 시간 리허설 (15-20분)
- [ ] 예상 질문 답변 연습
- [ ] 마이크/화면 공유 테스트

## 발표 중 팁

1. **숫자는 천천히** - 21.1%, 228만, 28%, 97만명
2. **핵심 문장에서 멈추기** - "OECD 1위", "0.1초"
3. **청중과 눈 맞춤** - 슬라이드만 보지 않기
4. **질문에 당황하지 않기** - "좋은 질문입니다"로 시작

## 발표 후 팁

- 질문이 없으면: "혹시 OOO 부분이 궁금하신 분 계실까요?"
- 모르는 질문: "좋은 지적입니다. 추가로 조사해서 반영하겠습니다."

---

**발표 성공을 응원합니다! 🎉**
